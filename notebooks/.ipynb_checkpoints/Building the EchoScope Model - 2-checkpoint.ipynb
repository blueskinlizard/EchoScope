{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a0ddaea-9836-4687-ac09-878bcff78cd3",
   "metadata": {},
   "source": [
    "# Building the EchoScope Model - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "953bfd37-41f4-438c-a95c-9aeae4b9d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7cf84b7-6358-40e5-a16b-2eb52f817a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5285b498-5d25-47ce-9c37-1a244ec7ab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir=\"runs/spectrogram_exp_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "363961dd-5b6e-41f1-b126-b5e0e84c705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IQ_Processed = np.load('../data/processed_iq_data.npz')\n",
    "Spectrogram_Processed = np.load('../data/spectrograms.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8159972-ce9d-431c-89bb-ca1d30463027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 220000\n",
      "Unique modulations: ['8PSK' 'AM-DSB' 'AM-SSB' 'BPSK' 'CPFSK' 'GFSK' 'PAM4' 'QAM16' 'QAM64'\n",
      " 'QPSK' 'WBFM']\n"
     ]
    }
   ],
   "source": [
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "for key_str in IQ_Processed.files:\n",
    "    key = ast.literal_eval(key_str)\n",
    "    mod_name = key[0]\n",
    "    data = IQ_Processed[key_str]\n",
    "    \n",
    "    X_list.append(data)\n",
    "    y_list.extend([mod_name] * data.shape[0])\n",
    "\n",
    "X = np.vstack(X_list)\n",
    "y = np.array(y_list)\n",
    "\n",
    "print(f'Total samples: {X.shape[0]}')\n",
    "print(f'Unique modulations: {np.unique(y)}')\n",
    "unique_modulations = np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db1c24bb-cfa9-4819-b84e-d3a5d5dedb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sets(X, y):\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val)\n",
    "    \n",
    "    print(f'Train shape: {X_train.shape}, {y_train.shape}')\n",
    "    print(f'Validation shape: {X_val.shape}, {y_val.shape}')\n",
    "    print(f'Test shape: {X_test.shape}, {y_test.shape}')\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d84db09-7c98-4206-9355-15976ca3120d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (132000, 2, 128), (132000,)\n",
      "Validation shape: (44000, 2, 128), (44000,)\n",
      "Test shape: (44000, 2, 128), (44000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = split_sets(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbc3eac9-3b9d-4b61-b325-39b4bfdf8512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8PSK' 'AM-DSB' 'AM-SSB' 'BPSK' 'CPFSK' 'GFSK' 'PAM4' 'QAM16' 'QAM64'\n",
      " 'QPSK' 'WBFM']\n"
     ]
    }
   ],
   "source": [
    "LE = LabelEncoder()\n",
    "y_train_enc = LE.fit_transform(y_train)\n",
    "y_val_enc = LE.transform(y_val)\n",
    "y_test_enc = LE.transform(y_test)\n",
    "\n",
    "print(LE.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15d05fab-7b8c-45f6-84f3-afab47d535c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_time = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train_enc, dtype=torch.long))\n",
    "val_dataset_time = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val_enc, dtype=torch.long))\n",
    "test_dataset_time = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test_enc, dtype=torch.long))\n",
    "\n",
    "train_loader_time = DataLoader(train_dataset_time, batch_size=64, shuffle=True)\n",
    "val_loader_time = DataLoader(val_dataset_time, batch_size=64, shuffle=False)\n",
    "test_loader_time = DataLoader(test_dataset_time, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c99611c5-47c1-4449-a161-2c02dd0c2188",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Time_Series_Model(nn.Module):\n",
    "    def __init__(self, input_size=128, hidden_size=32, output_size=11, num_layers=1, dropout=0.5):\n",
    "        super(Time_Series_Model, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=False,\n",
    "            dropout=0.0  \n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        last_out = lstm_out[:, -1, :]\n",
    "        out = self.dropout(last_out)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "269e9c53-ab27-4341-b288-f81f9091c402",
   "metadata": {},
   "outputs": [],
   "source": [
    "Time_Series_Model_V1 = Time_Series_Model()\n",
    "Time_Series_Model_V1 = Time_Series_Model_V1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6e3c5fb-2446-4e83-95eb-3fbcbceb27db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=1):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c8daa0a-f0a9-4b5c-bd1e-3617ba43166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def train_model(model, criterion, optimizer, epochs, train_loader, val_loader, patience=5, scheduler=None):\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    no_improve_epochs = 0\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * X_batch.size(0)\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item() * X_batch.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{epochs} | Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f}\")\n",
    "        writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
    "        writer.add_scalar(\"Loss/Val\", val_loss, epoch)\n",
    "        writer.add_scalar(\"LR\", optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            no_improve_epochs = 0\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "            if no_improve_epochs >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch} (best val loss: {best_val_loss:.6f})\")\n",
    "                break\n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "    model.load_state_dict(best_model_state)\n",
    "    return train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "173c71f4-e8ad-4505-89f9-f73e5073a39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 2.388333 | Val Loss: 2.354848\n",
      "Epoch 2/50 | Train Loss: 2.327306 | Val Loss: 2.280576\n",
      "Epoch 3/50 | Train Loss: 2.255591 | Val Loss: 2.201292\n",
      "Epoch 4/50 | Train Loss: 2.193607 | Val Loss: 2.143463\n",
      "Epoch 5/50 | Train Loss: 2.150877 | Val Loss: 2.106070\n",
      "Epoch 6/50 | Train Loss: 2.122958 | Val Loss: 2.081842\n",
      "Epoch 7/50 | Train Loss: 2.106184 | Val Loss: 2.066046\n",
      "Epoch 8/50 | Train Loss: 2.093800 | Val Loss: 2.055415\n",
      "Epoch 9/50 | Train Loss: 2.082397 | Val Loss: 2.047184\n",
      "Epoch 10/50 | Train Loss: 2.075003 | Val Loss: 2.041186\n",
      "Epoch 11/50 | Train Loss: 2.068880 | Val Loss: 2.036187\n",
      "Epoch 12/50 | Train Loss: 2.063343 | Val Loss: 2.031884\n",
      "Epoch 13/50 | Train Loss: 2.056228 | Val Loss: 2.028146\n",
      "Epoch 14/50 | Train Loss: 2.051057 | Val Loss: 2.024981\n",
      "Epoch 15/50 | Train Loss: 2.045896 | Val Loss: 2.022233\n",
      "Epoch 16/50 | Train Loss: 2.042582 | Val Loss: 2.019870\n",
      "Epoch 17/50 | Train Loss: 2.038370 | Val Loss: 2.017261\n",
      "Epoch 18/50 | Train Loss: 2.034570 | Val Loss: 2.015283\n",
      "Epoch 19/50 | Train Loss: 2.033325 | Val Loss: 2.013108\n",
      "Epoch 20/50 | Train Loss: 2.029645 | Val Loss: 2.011644\n",
      "Epoch 21/50 | Train Loss: 2.025206 | Val Loss: 2.009780\n",
      "Epoch 22/50 | Train Loss: 2.022334 | Val Loss: 2.008031\n",
      "Epoch 23/50 | Train Loss: 2.019433 | Val Loss: 2.006414\n",
      "Epoch 24/50 | Train Loss: 2.017338 | Val Loss: 2.005226\n",
      "Epoch 25/50 | Train Loss: 2.012839 | Val Loss: 2.003756\n",
      "Epoch 26/50 | Train Loss: 2.012548 | Val Loss: 2.002443\n",
      "Epoch 27/50 | Train Loss: 2.009955 | Val Loss: 2.001166\n",
      "Epoch 28/50 | Train Loss: 2.007695 | Val Loss: 2.000343\n",
      "Epoch 29/50 | Train Loss: 2.005370 | Val Loss: 1.999273\n",
      "Epoch 30/50 | Train Loss: 2.002998 | Val Loss: 1.998159\n",
      "Epoch 31/50 | Train Loss: 2.000466 | Val Loss: 1.997324\n",
      "Epoch 32/50 | Train Loss: 1.999833 | Val Loss: 1.996180\n",
      "Epoch 33/50 | Train Loss: 1.997986 | Val Loss: 1.995460\n",
      "Epoch 34/50 | Train Loss: 1.996831 | Val Loss: 1.994555\n",
      "Epoch 35/50 | Train Loss: 1.995102 | Val Loss: 1.993930\n",
      "Epoch 36/50 | Train Loss: 1.993545 | Val Loss: 1.993594\n",
      "Epoch 37/50 | Train Loss: 1.990937 | Val Loss: 1.992813\n",
      "Epoch 38/50 | Train Loss: 1.990559 | Val Loss: 1.992204\n",
      "Epoch 39/50 | Train Loss: 1.989617 | Val Loss: 1.991670\n",
      "Epoch 40/50 | Train Loss: 1.988786 | Val Loss: 1.991267\n",
      "Epoch 41/50 | Train Loss: 1.985982 | Val Loss: 1.990598\n",
      "Epoch 42/50 | Train Loss: 1.985148 | Val Loss: 1.990194\n",
      "Epoch 43/50 | Train Loss: 1.983066 | Val Loss: 1.989216\n",
      "Epoch 44/50 | Train Loss: 1.983987 | Val Loss: 1.988644\n",
      "Epoch 45/50 | Train Loss: 1.980602 | Val Loss: 1.988176\n",
      "Epoch 46/50 | Train Loss: 1.980137 | Val Loss: 1.987924\n",
      "Epoch 47/50 | Train Loss: 1.978722 | Val Loss: 1.987558\n",
      "Epoch 48/50 | Train Loss: 1.977424 | Val Loss: 1.987083\n",
      "Epoch 49/50 | Train Loss: 1.975918 | Val Loss: 1.987182\n",
      "Epoch 50/50 | Train Loss: 1.975995 | Val Loss: 1.986232\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(Time_Series_Model_V1.parameters(), lr=0.0001)\n",
    "train_losses, val_losses = train_model(model=Time_Series_Model_V1, criterion=nn.CrossEntropyLoss(), \n",
    "            optimizer=optimizer, epochs=50, train_loader=train_loader_time, \n",
    "            val_loader=val_loader_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21dc493-4869-4dec-a7d5-68df2a996c70",
   "metadata": {},
   "source": [
    "### Hyperparameter Trials: \n",
    "\n",
    "#### Trial 1: Complex model w/o dropout\n",
    "The model overfitted with the following hyperparameters: input_size=128, hidden_size=64, output_size=11, num_layers=1, dropout=0, learning_rate=0.0001, optimizer=Adam, loss_fn=CrossEntropyLoss, epochs=50, using a bidirectional LSTM without effective dropout due to num_layers=1.\n",
    "\n",
    "#### Trial 2: Complex model w/ dropout\n",
    "The model previously overfitted using the following configuration: input_size=128, hidden_size=64, output_size=11, num_layers=2, dropout=0.5, bidirectional=True, learning_rate=0.0001, optimizer=Adam, and CrossEntropyLoss. Despite enabling both internal and external dropout, validation loss steadily increased while training loss decreased, indicating the model capacity was too high for the dataset. This prompted a simplification of the architecture to reduce overfitting risk.\n",
    "\n",
    "#### Trial 3: Simplified model w/dropout\n",
    "The simplified model (input_size=128, hidden_size=32, output_size=11, num_layers=1, dropout=0.5, bidirectional=False, learning_rate=0.0001) showed significantly improved generalization compared to the previous overfitted configuration. Both training and validation loss decreased steadily over 50 epochs, confirming that reducing model complexity effectively mitigated overfitting and led to stable convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "734fd8f2-3300-4ce2-b36a-25efbadca28c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m epochs = \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m51\u001b[39m)\n\u001b[32m      2\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m6\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m plt.plot(epochs, \u001b[43mtrain_losses\u001b[49m, label=\u001b[33m'\u001b[39m\u001b[33mTraining Loss\u001b[39m\u001b[33m'\u001b[39m, marker=\u001b[33m'\u001b[39m\u001b[33mo\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m plt.plot(epochs, val_losses, label=\u001b[33m'\u001b[39m\u001b[33mValidation Loss\u001b[39m\u001b[33m'\u001b[39m, marker=\u001b[33m'\u001b[39m\u001b[33mo\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mTraining and Validation Loss over Epochs\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_losses' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, 51)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_losses, label='Training Loss', marker='o')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss', marker='o')\n",
    "plt.title('Training and Validation Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b03243cf-7eac-4662-aed4-e6d03853df88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"('QPSK', 2)\", \"('PAM4', 8)\", \"('AM-DSB', -4)\", \"('GFSK', 6)\", \"('QAM64', 8)\", \"('AM-SSB', 12)\", \"('8PSK', 8)\", \"('8PSK', 12)\", \"('QAM64', -6)\", \"('QAM16', 2)\", \"('QAM16', -20)\", \"('PAM4', -6)\", \"('WBFM', -18)\", \"('AM-DSB', 16)\", \"('CPFSK', 10)\", \"('WBFM', 6)\", \"('BPSK', 4)\", \"('BPSK', -2)\", \"('QPSK', -20)\", \"('CPFSK', -8)\", \"('AM-SSB', 6)\", \"('QAM64', -20)\", \"('QAM16', 12)\", \"('GFSK', -20)\", \"('AM-SSB', -12)\", \"('CPFSK', 0)\", \"('AM-DSB', 6)\", \"('BPSK', -16)\", \"('QPSK', -6)\", \"('8PSK', -12)\", \"('CPFSK', -18)\", \"('BPSK', -10)\", \"('QPSK', 8)\", \"('PAM4', 14)\", \"('AM-DSB', -10)\", \"('GFSK', 12)\", \"('QAM64', 2)\", \"('WBFM', -4)\", \"('AM-SSB', -18)\", \"('QAM64', -4)\", \"('GFSK', -4)\", \"('AM-DSB', 8)\", \"('PAM4', -16)\", \"('QPSK', -16)\", \"('BPSK', 16)\", \"('8PSK', -8)\", \"('CPFSK', 16)\", \"('WBFM', 0)\", \"('QPSK', 6)\", \"('BPSK', 14)\", \"('AM-DSB', -8)\", \"('GFSK', -10)\", \"('CPFSK', -2)\", \"('AM-SSB', 8)\", \"('GFSK', 18)\", \"('QAM16', 6)\", \"('QAM16', -16)\", \"('QAM64', 18)\", \"('AM-SSB', -2)\", \"('CPFSK', 6)\", \"('BPSK', 0)\", \"('BPSK', -6)\", \"('8PSK', -14)\", \"('CPFSK', -12)\", \"('AM-SSB', 2)\", \"('WBFM', 10)\", \"('AM-DSB', -12)\", \"('PAM4', 4)\", \"('GFSK', 10)\", \"('QAM16', -6)\", \"('QAM64', 4)\", \"('PAM4', -20)\", \"('8PSK', 10)\", \"('AM-SSB', -16)\", \"('QAM64', -10)\", \"('GFSK', -6)\", \"('AM-DSB', 2)\", \"('PAM4', -10)\", \"('QPSK', -2)\", \"('WBFM', -14)\", \"('WBFM', 12)\", \"('8PSK', 0)\", \"('QPSK', 12)\", \"('PAM4', 10)\", \"('AM-DSB', -14)\", \"('GFSK', 0)\", \"('QAM64', 14)\", \"('AM-SSB', 18)\", \"('QAM64', -8)\", \"('QAM16', 0)\", \"('GFSK', -16)\", \"('PAM4', -4)\", \"('QPSK', -12)\", \"('WBFM', -20)\", \"('CPFSK', 12)\", \"('WBFM', 4)\", \"('PAM4', 18)\", \"('BPSK', 10)\", \"('BPSK', -4)\", \"('QPSK', -18)\", \"('PAM4', -2)\", \"('CPFSK', -6)\", \"('AM-SSB', 4)\", \"('AM-DSB', -20)\", \"('8PSK', 16)\", \"('WBFM', 18)\", \"('QAM16', 10)\", \"('QAM16', -12)\", \"('CPFSK', 8)\", \"('8PSK', -16)\", \"('8PSK', -20)\", \"('AM-SSB', -6)\", \"('CPFSK', 2)\", \"('QPSK', 16)\", \"('AM-DSB', 4)\", \"('AM-DSB', -18)\", \"('8PSK', -10)\", \"('CPFSK', -16)\", \"('8PSK', -6)\", \"('QPSK', 10)\", \"('PAM4', 0)\", \"('BPSK', -20)\", \"('GFSK', 14)\", \"('QAM16', -2)\", \"('QAM64', 0)\", \"('8PSK', -4)\", \"('AM-SSB', -20)\", \"('QAM64', -14)\", \"('GFSK', -2)\", \"('AM-DSB', 14)\", \"('PAM4', -14)\", \"('QPSK', -14)\", \"('WBFM', -10)\", \"('CPFSK', 18)\", \"('8PSK', 4)\", \"('QPSK', 0)\", \"('BPSK', 12)\", \"('AM-DSB', -2)\", \"('GFSK', 4)\", \"('QAM64', 10)\", \"('AM-SSB', 14)\", \"('WBFM', 8)\", \"('QAM16', -10)\", \"('PAM4', 16)\", \"('QAM16', 4)\", \"('QAM16', 18)\", \"('QAM16', -18)\", \"('QAM64', 16)\", \"('PAM4', -8)\", \"('WBFM', 16)\", \"('WBFM', 14)\", \"('AM-SSB', -4)\", \"('QAM16', -4)\", \"('BPSK', 6)\", \"('BPSK', -8)\", \"('BPSK', 18)\", \"('CPFSK', -10)\", \"('AM-SSB', 0)\", \"('PAM4', 6)\", \"('QAM64', -18)\", \"('QAM16', 14)\", \"('QAM16', -8)\", \"('PAM4', -18)\", \"('AM-DSB', 18)\", \"('AM-SSB', -10)\", \"('QAM64', -12)\", \"('AM-DSB', 0)\", \"('BPSK', -14)\", \"('QPSK', -8)\", \"('WBFM', -16)\", \"('CPFSK', -20)\", \"('8PSK', 2)\", \"('QPSK', 14)\", \"('PAM4', 12)\", \"('AM-DSB', -16)\", \"('GFSK', 2)\", \"('QAM64', 12)\", \"('AM-SSB', 16)\", \"('QAM64', -2)\", \"('8PSK', 14)\", \"('GFSK', -14)\", \"('AM-DSB', 10)\", \"('WBFM', -8)\", \"('QPSK', -10)\", \"('CPFSK', 14)\", \"('WBFM', 2)\", \"('QPSK', 4)\", \"('BPSK', 8)\", \"('AM-DSB', -6)\", \"('CPFSK', -4)\", \"('AM-SSB', 10)\", \"('WBFM', -2)\", \"('8PSK', 18)\", \"('QAM16', 8)\", \"('QAM16', -14)\", \"('8PSK', -18)\", \"('8PSK', -2)\", \"('AM-SSB', -8)\", \"('CPFSK', 4)\", \"('QPSK', 18)\", \"('BPSK', 2)\", \"('BPSK', -12)\", \"('WBFM', -6)\", \"('CPFSK', -14)\", \"('GFSK', 16)\", \"('PAM4', 2)\", \"('GFSK', 8)\", \"('GFSK', -12)\", \"('QAM64', 6)\", \"('GFSK', -18)\", \"('AM-SSB', -14)\", \"('QAM64', -16)\", \"('QAM16', 16)\", \"('GFSK', -8)\", \"('AM-DSB', 12)\", \"('PAM4', -12)\", \"('QPSK', -4)\", \"('WBFM', -12)\", \"('8PSK', 6)\", \"('BPSK', -18)\"]\n",
      "Data shape for ('QPSK', 2): (1000, 2, 17, 7)\n"
     ]
    }
   ],
   "source": [
    "keys = Spectrogram_Processed.files\n",
    "print(keys)\n",
    "\n",
    "key_example = \"('QPSK', 2)\"\n",
    "if key_example in keys:\n",
    "    data = Spectrogram_Processed[key_example]\n",
    "    print(f\"Data shape for {key_example}:\", data.shape)\n",
    "else:\n",
    "    print(f\"{key_example} not found in the file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7281727b-fc97-4a85-a0a6-f9358936b3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9MAAAGGCAYAAAB40dIoAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAATrJJREFUeJzt3Ql8VNX5//FnEsgKCfsSDZsgi6yCUHDDikWkiFZRrC0Bt2pFxFARWlaRRnBDlL+IG9JitYvg1qIomwuigChaCIRFIgJRkYQEsjAz/9c5/maaQEJyZ+Zm7pn5vPs6TeZmbnITSb7z3LO5vF6vVwAAAAAAQI3F1PypAAAAAABAoZgGAAAAAMAiimkAAAAAACyimAYAAAAAwCKKaQAAAAAALKKYBgAAAADAIoppAAAAAAAsopgGAAAAAMAiimkAAAAAACyimEZEcLlcMnbsWImk72fGjBnhvgwAAEKOzAYQKSim4Wi7du2S3/3ud9KuXTtJSEiQlJQUOf/88+Xxxx+X48ePh/vyHOG5556Tzp07659Phw4d5Iknngj3JQEAohCZfXpPPfWUjBgxQlq1aqUL8NGjR4f7kgAEqU6wnwCwy1tvvaVDJz4+XkaNGiVdu3aV0tJS+eCDD+Tee++Vr776ShYtWiTR7Omnn5bbb79drrnmGsnMzJT3339fxo0bJ8eOHZP77rsv3JcHAIgSZHb15syZI0ePHpW+ffvKgQMHwn05AEKAYhqOtGfPHhk5cqS0bt1aVq1aJS1btvR/7M4775ScnBwd3NFM3eX/05/+JEOHDpV//vOf+titt94qHo9HZs2aJbfddps0bNgw3JcJAIhwZHbNrF271t8rXa9evXBfDoAQYJg3HGnu3LlSWFiohzCXD2Wf9u3by913333K8eXLl+u74erO+DnnnCMrVqyo8PGvv/5afv/730vHjh0lMTFRGjdurO+k7927t8LzFi9erMPuww8/1D2+TZs2leTkZLn66qvlu+++q/DcNm3ayC9/+Ut9913dbVZD29QQtyVLlpxyfUeOHJHx48dLenq6vkb1fag71aoAtmr16tXyww8/6O+nPPXCpaioiBcuAIBaQWbXjLrZoK4TQOSgmIYjvfHGGzrcBgwYUONzVDCq0FV3x1WwFxcX6+HPquD0+fTTT+Wjjz7Sz5k/f74eIv3ee+/JwIED9dDok911113y+eefy/Tp0+WOO+7Q11XZoinqrvu1114rl112mTzyyCO6R1jNhVLD2nzU57/44ovlr3/9qx4Cp76+mks2efJkHf5WffbZZ/ptnz59Khzv3bu3xMTE+D8OAICdyGwAUcsLOEx+fr5X/dMcPnx4jc9Rz4+Li/Pm5OT4j33++ef6+BNPPOE/duzYsVPOXb9+vX7ekiVL/MdeeOEFfWzQoEFej8fjP37PPfd4Y2NjvUeOHPEfa926tX7uunXr/Mfy8vK88fHx3gkTJviPzZo1y5ucnOzdsWNHha8/adIk/Tn37dtX4fuZPn36ab/nO++8U59XmaZNm3pHjhx52vMBAAgWmV2zzD6Z+twZGRmWzgHgPPRMw3EKCgr02/r161s6b9CgQXLWWWf5H3fv3l2vJLp7927/MTVMzKesrEzfAVfDtho0aCCbN28+5XOqecflh2RdeOGF4na79dCz8rp06aI/5qOGmKlhaeW/9j/+8Q/9HHUH/Pvvv/c3dd3qc65bt87ynOm4uLhKP6aGrbFyKgDAbmQ2gGjGAmRwHBWmilrx0gq1qMfJVAj++OOP/seqwMzKypIXXnhB9u/fr0Zm+D+Wn59f7ef0LehV/nPW9Gvv3LlTvvjiCx3alcnLyxMr1IsMtVJqZdRwufIvQgAAsAOZDSCaUUzDkcGclpYmX375paXzYmNjKz1ePnzVfCoVympBkf79+0tqaqq+i63mY1W2oEhNPmdNn6c+v5qfNXHixEqfe/bZZ4sVapEXdXdcBXqzZs38x1WBre7eq58hAAB2IrMBRDOKaTiSWmlT7Ue5fv16HaChoraQysjI0AuOlO/FVSt22k0NZ1OrnaohYqHQs2dP/Xbjxo1yxRVX+I+rx+pFgO/jAADYicwGEK2YMw1HUneC1bYWt9xyixw6dOiUj+/atUsef/xxy59X3Y0++Q71E088oXt47XbdddfpFxpvv/32KR9TLwxOnDhh6fP9/Oc/l0aNGslTTz1V4bh6nJSUpPefBgDAbmQ2gGhFzzQcSd0Rfumll+T666+Xzp07620p1F6Uagiz2iZDLQyitrEI5O75X/7yFz1UTC1AooLy3Xff1XtX2u3ee++V119/XV+Duna1hZXaD3rr1q367rvaN7NJkyY1/nxqTvSsWbP0vtJq383BgwfL+++/r7fxmD17ti60AQCwG5ldM2qrLrV1l29BNTUn+4EHHtCPr7zySr0IGwCzUEzDsVSwqKB56KGH5LXXXtM9rvHx8Tps1JCvW2+91fLnVHfG1Z3upUuX6qFias9IFcyqELWb6i1eu3at/PnPf9YvLJYsWaLnmql5VzNnztQvFqxSe3TWrVtX/zxU6Kenp8tjjz0md999ty3fAwAAlSGzq/evf/1LXnzxRf/jzz77TDflzDPPpJgGDORS+2OF+yIAAAAAADAJc6YBAAAAALCIYhoAAAAAAIsopgEAAAAAsIhiGgAAAAAAiyimAQAAAACwiGIaAAAAAADT95n2eDzy7bffSv369cXlcoX7cgDAWGrnw6NHj0paWprExITu3qna77W0tDSozxEXFycJCQkhuyaEB5kNAJGd2eS1YcW0CuX09PRwXwYARIzc3Fw588wzQxbKbVvXk4N57qA+T4sWLWTPnj0EtOHIbACI7Mwmrw0rptXdbSUt648SY+p/tITgXmQ6QezhumK62CKzZzEkH/CK6Qo6mP09eBoH1/sabp7jJbJ//Bz/39VQUHe3VSh/vamNpNQP7Hes4KhHWvfeqz8X4Ww237+t7tdOldi6Zv63/L6PR0wXU2z+qICkdgVissS6ZWK6lGt3i8li6tcTk53wlsm6wr87KrPJawOLad8wMVVIxyQa+h8tAorpmIQIKKbdZhfTsXFmF6JKTILh30Oi2f+GfOwYfluvvku3QHjE/Bf+qPhvSxXSsXFmZnZMYgQU0xHwOxWbVCImi40zPy/quMx+7RfjipNI4KTMJq8NLKYBAM7n9nrE7Q38XAAA4OzMJq+rZ/5tNABArfOIN6hmxbp162TYsGF6URZ1x3758uWnff6aNWv0805uBw8eDPK7BgDAPLWV19HIcjFdkxc127ZtkyuvvFJSU1MlOTlZzjvvPNm3b1+orhkAEGaeIP9nRVFRkfTo0UMWLFhg6bzs7Gw5cOCAvzVr1kyiCXkNAFBqK6+jkeVh3r4XNTfddJP86le/OuXju3btkgsuuEBuvvlmmTlzpqSkpMhXX33FpHUAQECGDBmim1WqeG7QoIFEK/IaAACHFdPVvaj505/+JFdccYXMnTvXf+yss84K/AoBAI7j9np1C/Tc2tCzZ08pKSmRrl27yowZM+T888+XaEJeAwCCyezaymuThXTOtMfjkbfeekvOPvtsGTx4sO4V6NevX7Xz2wAA0TdnuqCgoEJThW8otGzZUhYuXCj/+te/dFP7IA8cOFA2b94cks8fCchrAIgezJk2pJjOy8uTwsJCefDBB+Xyyy+Xd955R66++mo9vGzt2rWVnqNePJ38ggoA4GwqYN0BNl84qyJXzdX1taysrJBcW8eOHeV3v/ud9O7dWwYMGCDPP/+8fvvYY4+F5PNHgkDyWiGzASB6Mptiupa3xlJ3upXhw4fLPffc4x9m99FHH+legosvvviUc9SLJzVXCwBgjmDuWPvOy83N1fN0feLj48Uuffv2lQ8++MC2z2+aQPJaIbMBIHoym2K6lnummzRpInXq1JEuXbpUON65c+cqVwedPHmy5Ofn+5t6cQUAiHyqkC7f7Cymt2zZood/I/C8VshsAABs6pmOi4vT22qo7UjK27Fjh7Ru3brSc9SLJztfQAEAzF6ATA1HzsnJ8T/es2ePLo4bNWokrVq10gXe/v37ZcmSJfrj8+bNk7Zt28o555wjxcXF8uyzz8qqVav0UGYEntcKmQ0A5mEBMgcV09W9qLn33nvl+uuvl4suukguueQSWbFihbzxxhuyZs2aUF87ACBM1CDhQHeftHrexo0bdZ74ZGZm6rcZGRmyePFivYd0+d7U0tJSmTBhgi6wk5KSpHv37vLuu+9W+BzRgLwGAAST2VbPWbdunTz00EOyadMmnc3Lli2Tq666qsrnq7ypLJvVuS1atJCILKare1GjFjBR863UvKpx48bphWDUaqpqL0sAQGTwLU4S6LlWqJW4vae5O66yp7yJEyfqFu3IawBAMJlt9ZyioiLp0aOH3HTTTXpBy5pSo6TKr6GidpgwheViuroXNYr6AaoGAADCg7wGANSmIUOG6GaVKp4bNGggEu0LkAEAooPbG1wDAAC1w+l53bNnT71I6GWXXSYffvihRO0CZACA6FCbc6YBAED45kwXFBTYshhly5Yt9XSjPn36SElJiV4wVI2q2rBhg5x77rliAoppAIBlHnGJW1wBnwsAAJyd2b68Tk9Pr3B8+vTpMmPGjKCvS63VoZrPgAEDZNeuXfLYY4/JX/7yFzGBY4vp2GMxEuMxcxR68nbH/lhrzBMnxnO5xWhHupg/FtZbx+zvISbP8C2Aiu37+Xu8P7VAz0VkqTMiT+okm/n7UudIPTGd+2CSmC4xrkxMdqy0rpjux9n9xWRNeh8Sk50oKhGp+ZpdtZLZvnNyc3MrLBBm5xaJffv2lQ8++EBMYX7VBwAAAACwhSqkyxfTdtqyZYse/m0KimkAgGXuIIZ5B3oeAACovcy2ek5hYaHk5OT4H+/Zs0cXx40aNZJWrVrJ5MmTZf/+/bJkyRL98Xnz5knbtm3lnHPOkeLiYj1netWqVfLOO++IKSimAQCWUUwDAGCG2iqmN27cKJdccon/cWZmpn6bkZEhixcvlgMHDsi+ffv8Hy8tLZUJEyboAjspKUm6d+8u7777boXP4XQU0wAAyzxel26BngsAAJyd2VbPGThwoHi9VU/OVgV1eRMnTtTNZBTTAADL6JkGAMAMtdUzHY3MXC4bAAAAAIAwomcaAGCZW2J0C+xcAADg9Mwmr6tHMQ0AsMwbxJxpdS4AAHB2ZpPX1aOYBgBYxpxpAADMwJxp+1BMAwAsc3tjdAvs3JBfDgAACHFmk9fVYwEyAAAAAAAsomcaAGCZR1ziCfB+rEe41Q0AgNMzm7yuHsU0AMAy5kwDAGAG5kzbh2IaAFDLc6a50w0AgPPnTJPX1aGYBgAEOGQssDvWgZ4HAABqL7PJ6+qxABkAAAAAABbRMw0AsEwtZOJmATIAACI2s8nr6lFMAwAsY840AABmYM50FBbT7kSPeBM9YqKC7ifEdHHf1hXTuTxmz/NIPGj+LIwTiWK0kjNKxWSe42X2fW6JYWss+B05liixEi8mavjvZDHdD93EePXmpojJCi5MENOVppn9+rXMHSsmc3tiHZfZ5HX1zH+1DgAAAABALXNszzQAwLncXpdugZ4LAACcndnkdfUopgEAlrmDWIDMzbAxAAAcn9nkdfUopgEAlnm8MboFdi7hDACA0zObvK6e5Z/qunXrZNiwYZKWliYul0uWL19e5XNvv/12/Zx58+ZZ/TIAAAPucgfaYD/yGgCgkNf2sfwTKioqkh49esiCBQtO+7xly5bJxx9/rEMcAADULvIaAACHDfMeMmSIbqezf/9+ueuuu+Ttt9+WoUOHBnN9AAAH8gSxMImZmx6ah7wGAAST2eR1GOZMezwe+e1vfyv33nuvnHPOOaH+9AAABwhun2mGjTkBeQ0A0SHwfabJ61ovpufMmSN16tSRcePG1ej5JSUluvkUFBSE+pIAACHm9sboFui5CD+rea2Q2QAQPZlNXtdyMb1p0yZ5/PHHZfPmzXohk5rIysqSmTNnhvIyAAA284hLt0DPRXgFktcKmQ0A0ZPZ5HX1Qnq74f3335e8vDxp1aqVvtut2tdffy0TJkyQNm3aVHrO5MmTJT8/399yc3NDeUkAACAEea2Q2QAA2NQzreZeDRo0qMKxwYMH6+Njxoyp9Jz4+HjdAADmYJi32QLJa4XMBgDzMMzbQcV0YWGh5OTk+B/v2bNHtmzZIo0aNdJ3uBs3blzh+XXr1pUWLVpIx44dQ3PFAICwC2b/SfatrB3kNQAgmMwmr20opjdu3CiXXHKJ/3FmZqZ+m5GRIYsXL7b66QAABvJ4XboFei7sR14DAILJbPLahmJ64MCB4vV6a/z8vXv3Wv0SAACHU9tlBHrHmq02agd5DQAIJrPJ6+rxEwIAAAAAINz7TAMAIp/HG6NboOcCAABnZzZ5XT2KaQCAZW5x6RbouQAAwNmZTV4bXEzH/RArsQmxYqITSebfxYntfFRM53ab/d/h+LdJYrqYUrP/CCfujROTuUs8tn1ueqZR3onSWPHUcexLitNym/1rriX8YPbfWmXXjWa+5vNxHXeL6ermm/3fIL8wUUzmOWbf7zE90/bhJwQAcLR169bJsGHDJC0tTVwulyxfvrzac9asWSPnnnuu3hO5ffv2rF4NAABCjmIaAGCZu9ywMevNmqKiIunRo4csWLCgRs9X+ykPHTpUbwul9lUeP3683HLLLfL2228H9L0CABCdmY3qmDkmCwAQVrU5zHvIkCG61dTChQulbdu28sgjj+jHnTt3lg8++EAee+wxGTx4sOXrBQDAZAzztg8/IQCAZW5vTFDNTuvXr5dBgwZVOKaKaHUcAIBoU1t5vS4Kp2VRTAMALPOKSzwBNnWuUlBQUKGVlJSE5NoOHjwozZs3r3BMPVZf4/jx4yH5GgAARHpm+/K6poqicFoWw7wBAGGRnp5e4fH06dNlxowZYbseAAAQuCFROC2LYhoAYFkww7V95+Xm5kpKSor/uBriFQotWrSQQ4cOVTimHquvlZho9tYpAADUVmaHa1rW+PHjxRQU0wAAyzxel26Bnquo4rZ8MR0q/fv3l3//+98Vjq1cuVIfBwAg2gSa2b5z1DSp8tTN71DcAD9YzbQsE26AM2caAGCZW2KCalYUFhbquVSq+eZYqff37dunH0+ePFlGjRrlf/7tt98uu3fvlokTJ8r27dvl//2//yd///vf5Z577gnxTwEAAOcLNq/VtKzU1FR/y8rKCve35Bj0TAMAwtIzXVMbN27Ui5P4ZGZm6rcZGRl61c8DBw74C2tFzb966623dPH8+OOPy5lnninPPvusMfOvAABwUs8007KqRjENAHC0gQMHitfrrfLjlW2joc757LPPbL4yAAAiH9OyqsYwbwCAZR6JCaoBAIDaUVt5XRiF07LomQYAWOb2unQL9FwAAODszLZ6zsYonJZFMQ0AcPScaQAAEL450zU1MAqnZVFMAwAs83pjxBPg/pPqXAAA4OzMJq+rx08IAAAAAACL6JkGAFjmFpdugZ4LAACcndnkdfUopgEAlnm8gc99VucCAABnZzZ5bXAx7T3rmHiSPGKi+u8ni+kKYuuJ8ZqUiMlSd5h/N9AbY/b3UGfI92Iy9zH7fgc8QcyZDvQ8OFdZcV2JcdUVE/3YxfxXi42/EOMdO4O/C+F2or6Zr7t94rYb/tq1uI7jMpu8rh4/IQAAAAAAIqVnGgDgXB5x6RbouQAAwNmZTV5Xj2IaAGCZ2+vSLdBzAQCAszObvK4exTQAwDLmTAMAYAbmTNuHYhoAENiQsUBX82bYGAAAjs9s8rp6lm83rFu3ToYNGyZpaWnicrlk+fLl/o+VlZXJfffdJ926dZPk5GT9nFGjRsm3335r9csAAIAgkNcAADismC4qKpIePXrIggULTvnYsWPHZPPmzTJ16lT99tVXX5Xs7Gy58sorQ3W9AAAH8P7fYiaBNHUu7EdeAwCCyWzy2oZh3kOGDNGtMqmpqbJy5coKx5588knp27ev7Nu3T1q1amX1ywEAHEgNFwt4mDcLmtQK8hoAEExmk9cOmDOdn5+vh5c1aNCg0o+XlJTo5lNQUGD3JQEAgsQCZJGnurxWyGwAMA8LkNnH1p9QcXGxnpN1ww03SEpKSqXPycrK0nfIfS09Pd3OSwIAhPAud6ANzlKTvFbIbAAwD3ltYDGtFje57rrrxOv1ylNPPVXl8yZPnqzvhvtabm6uXZcEAAACzGuFzAYAwOZh3r5g/vrrr2XVqlWnvcsdHx+vGwDAHL7FSQI9F85gJa8VMhsAoiezyeswFNO+YN65c6esXr1aGjduHOovAQAIMxYgMx95DQDRgQXIHFRMFxYWSk5Ojv/xnj17ZMuWLdKoUSNp2bKlXHvttXqbjTfffFPcbrccPHhQP099PC4uLrRXDwAIC4pp5yOvAQAKxbSDiumNGzfKJZdc4n+cmZmp32ZkZMiMGTPk9ddf14979uxZ4Tx113vgwIHBXzEAIOwopp2PvAYAKBTTDiqmVcCqRUqqcrqPAQCA2kFeAwBg+D7TAIDIQ880AABmoGfaPhTTAADLvEGs8kl/KAAAzs9s8trgYtrtjhGv27ZtsG119PzjYrq4HYliOndJgpisKE2MV9bQLSaLP272FkDu4/bFID3TKC+5wXGJTfKIiY7VNfv3XDl2ZamYzvtdkpisXk5dMV1pA7NLJ8/ZRWIy77Fi2z43PdP2MbNaBQAAAAAgjBzbMw0AcC56pgEAMAM90/ahmAYAWEYxDQCAGSim7UMxDQCwjGIaAAAzUEzbh2IaAGCZ1+vSLdBzAQCAszObvK4eC5ABAAAAAGARPdMAAMvUfpWB7jMd6HkAAKD2Mpu8rh7FNADAMuZMAwBgBuZM24diGgBgGXOmAQAwA3Om7UMxDQCwjJ5pAADMQM+0fViADAAAAAAAi+iZBgBYxjBvAADMwDBv+1BMAwACCthAh38RzgAAOD+zyevqMcwbAGCZV4dsgC3cFw8AQBQJOLMD/HoLFiyQNm3aSEJCgvTr108++eSTKp+7ePFicblcFZo6zxT0TAMAAtp7Uv0v0HMBAICzMzuQvH7llVckMzNTFi5cqAvpefPmyeDBgyU7O1uaNWtW6TkpKSn64z6qoDYFPdMAAAAAgKA9+uijcuutt8qYMWOkS5cuuqhOSkqS559/vspzVPHcokULf2vevLmYgmIaABDwYiaBNquiacgYAAChFGxeFxQUVGglJSWVfp3S0lLZtGmTDBo0yH8sJiZGP16/fn2V11dYWCitW7eW9PR0GT58uHz11VdiCoppAEDAe1YG2gIZMjZ9+nTZvHmz9OjRQw8Zy8vLq/IcNWTswIED/vb111+H4LsGAMA8wea1KnJTU1P9LSsrq9Kv8/3334vb7T6lZ1k9PnjwYKXndOzYUfdav/baa/LXv/5VPB6PDBgwQL755hsxgWPnTJ/bJlfqJseJiTav7SimK6vvEdPVLTD7XlFJU7eYru6PZv83qHOG2f8NXHXs+z32LU4S6LmBDhlT1JCxt956S4fvpEmTTjtkDLWjZGeKxBja+1/vkDlz86pScE6smK5f111isq17O4npylIMf+1Xavbvgacs1nGZ7TsnNzdX36T2iY+PD9m19e/fXzcfVUh37txZnn76aZk1a5Y4ndmvdAEAxg7zrsmwsWgcMgYAQCgFm9eqkC7fqiqmmzRpIrGxsXLo0KEKx9Xjmt7grlu3rvTq1UtycnLEBBTTAICwqMmwsWgcMgYAgIni4uKkd+/e8t577/mPqQxWj8v3Pp+OyvytW7dKy5YtxQSOHeYNAHCuQBcS851r57Ax04eMAQDghMwO5JzMzEzJyMiQPn36SN++ffXWWEVFRf6pWqNGjZIzzjjDfwP9/vvvl5/97GfSvn17OXLkiDz00EN6nZNbbrlFTEAxDQCwTC1K4gqwmPYtaOIbLnY60ThkDAAAJ2S21QVDleuvv16+++47mTZtmh5B1rNnT1mxYoV/hNm+ffv0dC2fH3/8Ua+Lop7bsGFD3bP90Ucf6W21TEAxDQBw7AJk5YeMXXXVVRWGjI0dO9bSkLErrrgisAsGAMBgwS5AZtXYsWOrzOg1a9ZUePzYY4/pZirLc6bXrVsnw4YNk7S0NL1a6vLlyyt83Ov16jsRapx7YmKiXiRm586dobxmAEAUUUPGnnnmGXnxxRdl27Ztcscdd5wyZGzy5Mn+56shY++8847s3r1bb6X1m9/8xqghY6FCXgMA4LBiWr2AUXt8LliwoNKPz507V+bPn6+3LtmwYYMkJyfr/UCLi4tDcb0AAMfc5Q50dVDrQ8YefvhhXfip4WJbtmw5ZciY2kv65CFjap606o1WK4WbNGQsVMhrAEBwmR3uK4/AYd5DhgzRrTLqLreaZD5lyhS9FYmyZMkS/YJH3REfOXJk8FcMAIiIBcisiKYhY6FCXgMAansBsmgT0q2x9uzZoyePl98PVG130q9fvyr3A1X7ip681ygAwNm8QTaEVyB5rZDZAGAe8tqQYtq356eV/UDVsujl9xlV+44CAJwt8CHegfdoI7x5rZDZAGAe8tqQYjoQatGY/Px8f1P7jgIAAOchswEAsGlrLN+en2r/T7U6qI96rBaNqUx8fLxuAACDBDP+i3FjYRdIXitkNgAYKNDMJq9rt2e6bdu2OqDV/p8+aj6VWiW0f//+ofxSAIBwCmbIGMPGwo68BoAoQl47p2e6sLBQcnJyKixiorYpadSokbRq1UrGjx8vDzzwgHTo0EGH9dSpU/Uel1dddVWorx0AENZtNgI/N5KpraUSEhLCfRnkNQAgqMwmr23omd64caP06tVLNyUzM1O/r/b/VCZOnCh33XWX3HbbbXLeeefpMFf7gTrhhQUAIDRYgKwij8cjs2bNkjPOOEPq1asnu3fv1sdVgfrcc8+F5ZrIawCAQl7bl9eWi+mBAwfq/SlPbosXL9Yfd7lccv/99+vVQFW1/+6778rZZ59t+cIAADCF6uFVOTh37lyJi4vzH+/atas8++yzYbkm8hoAAHvzOuyreQMADOSbSxVoizBLliyRRYsWyY033iixsbH+4z169JDt27eH9doAAFGOvLYtr0O6mjcAIDowZ7qi/fv3S/v27SsdTlZWVhaWawIAQGHOtH157dhiOudwE4ktNnP7DZdHjOfymH8nKuaEGC3+u//dLTNVaUOzfxk8x/83/MdEnuM2/vzZGquCLl26yPvvvy+tW7eucPyf//ynf85yJDuR6paYRLeYqP6n5uedXFwkptv4sdlTDJpedEhMV/JjfTGZu9ixZU2NeN02Dhhmayzb8trsf3UAgLAIZmGSSFzQRC3qlZGRoe94q7vbr776qmRnZ+vhZG+++Wa4Lw8AEMUCzWzyunrMmQYAIEjDhw+XN954Qy/ilZycrMN627Zt+thll10W7ssDAAAS+rymZxoAEJgIHP4VjAsvvFBWrlwZ7ssAAOBUZLYteU0xDQCwjGHeAACYgWHe9qGYBgBYxwJk0rBhQ71Xc00cPnzY9usBAKBSUb4AWUMb85piGgCAAMybN8///g8//CAPPPCADB48WPr376+PrV+/Xt5++22ZOnVqGK8SAIDoNs/GvKaYBgAEQN3hDXT4V2QMG1Orgfpcc801cv/998vYsWP9x8aNGydPPvmkXuTknnvuCdNVAgAQaGaT19VhNW8AQOBDxgJtEUbd0b788stPOa6OqXAGACBsyGvb8ppiGgBgHcV0BY0bN5bXXnvtlOPqmPoYAABhQ17bltcM8wYAWKdW+Ax0lc8IXB105syZcsstt8iaNWukX79++tiGDRtkxYoV8swzz4T78gAA0SzQzCavq0UxDQBAkEaPHi2dO3eW+fPny6uvvqqPqccffPCBP6wBAEBk5TXFNADAMq/3pxbouZFIhfDSpUvDfRkAAIQks8nr6lFMAwCsY5/pCvbt23faj7dq1arWrgUAgAqifJ9pO/OaYhoAYB1zpito06aNuFxVf19ut7tWrwcAAD/mTNuW1xTTAADLXN6fWqDnRprPPvuswuOysjJ97NFHH5XZs2eH7boAAAg0s8nr6lFMAwAQpB49epxyrE+fPpKWliYPPfSQ/OpXvwrLdQEAAPvymmIaAGAdc6ZrpGPHjvLpp5+G+zIAANGMOdO25TXFNADAOuZMV1BQUFDhsdfrlQMHDsiMGTOkQ4cOYbsuAACYM21fXlNMAwCso2e6ggYNGpyyoIkK6PT0dHn55ZfDdl0AANAzbV9eO7aYPrqzocQkJIiJ4jtXvONhopgNqWK6oq7FYrKYvDgxXf3dMWKyo2Lm3yAfj52/AhTTFaxevbrC45iYGGnatKm0b99e6tRxbNSGTMO0fIlNMvNv7sEBjcR0SWK+xANm50W95Sliuu+Hmp158e0KxWTumBL7PjnFtG15HfkJDwCAzdRd7gEDBpwSxCdOnJB169bJRRddFLZrAwAA9uS12bcBAQDh4Q2yRZhLLrlEDh8+fMrx/Px8/TEAAMKGvLYtr+mZBgBYxwJkp8y3OnkOlvLDDz9IcnJyWK4JAACNBchsy2uKaQCAZS7vTy3QcyOFbz9KFcyjR4+W+Ph4/8fcbrd88cUXejgZAACmZXageb1gwQK9Z/PBgwf1vs5PPPGE9O3bt8rn/+Mf/5CpU6fK3r179Yrac+bMkSuuuEJMyOuQD/NWF6N+GG3btpXExEQ566yzZNasWfouAAAAkSQ1NVU3lXH169f3P1atRYsWctttt8lf//pXcSLyGgAQaq+88opkZmbK9OnTZfPmzbqYHjx4sOTl5VX6/I8++khuuOEGufnmm+Wzzz6Tq666Srcvv/zSiLwOec+0upPw1FNPyYsvvijnnHOObNy4UcaMGaMvdNy4caH+cgCAcGA1b+2FF17Qb9u0aSN/+MMfjBrSTV4DQJSoxdW8H330Ubn11lt1nigLFy6Ut956S55//nmZNGnSKc9//PHH5fLLL5d7771XP1Y3dVeuXClPPvmkPtfpeR3yYlrdXRg+fLgMHTrUf8F/+9vf5JNPPgn1lwIAwBHUHXjTkNcAgJooKKi47a8aIl1+mLRPaWmpbNq0SSZPnlxh66lBgwbJ+vXrpTLquOrJLk/1ZC9fvlxMyOuQF9NqrPmiRYtkx44dcvbZZ8vnn38uH3zwgb5LUZmSkhLdqvqPBQBwHrV0R8BzpiUynHvuufLee+9Jw4YNpVevXpUuaOKjhro5jdW8VshsAIiezPalWnp6+ikF6YwZM055/vfff6+nEDVv3rzCcfV4+/btlX4NNa+6suer4ybkdciLadV9r8K1U6dOEhsbq3+gs2fPlhtvvLHS52dlZcnMmTNDfRkAADuxmrfu1fXdmVfzu0xjNa8VMhsAom8179zcXElJSfEfrqxXOlrzOuTF9N///ndZunSpvPTSS3oO1pYtW2T8+PGSlpYmGRkZpzxfDQMo37Wvgv3kux8AADhN+aFiJg7ztprXCpkNANFHFdLli+mqNGnSRN+cPXToUIXj6rFa5Ksy6riV5zstr0NeTKvJ4+pu98iRI/Xjbt26yddff63vZlcWzlWNuQcAOBgLkFVKzRdTK5Z6PJ4Kx1u1aiVOYzWvFTIbAAxUSwuQxcXFSe/evfWQal8PsMpD9Xjs2LGVntO/f3/9cXUz10ctQKaOm5DXId8a69ixY3qieXnqDsXJFwoAiIBgDrQFsGelWiArISFB+vXrV+0iWWrPSjV8WT1fFYn//ve/xU5q3vGFF16ot5hq3bq13m5KNXXN6q0TkdcAECVqMa8zMzPlmWee0TtFbNu2Te644w4pKiryr+49atSoCguU3X333bJixQp55JFH9LxqNRdb7S5RVfHttLwOec/0sGHD9JwrVdWrYWNqvzC1mMlNN90U6i8FAAgTtZBJwAuQeQPbs1JtkaEK6Xnz5umVPrOzs6VZs2ZV7lmpelh/+ctf6mHM6g65WlSka9euYgf1IqFOnTry5ptvSsuWLU+7uIlTkNcAEB0CzexAzrn++uvlu+++k2nTpulFxHr27KmLZd8iY/v27atwI1cthqlyesqUKfLHP/5ROnTooFfyNiWvXV61c3UIHT16VKZOnSrLli3TXedq7pV6UaN+oKrrvzpq/pXa47L1A7MlJiFBTBTfzvzVTWM2pIrpiroWi8li8qr/fXG6el+HfPBLrTrazuweOk9xseybNEXy8/NrNNepJnx/o9sE8TdaXdfeKX+q8XWpAvq8887Te07q8z0ePU/3rrvuqnTPShXk6i64Ckqfn/3sZzrQQ7lnZXlqv0q1HYjqDTdFsHld/t9Dt79PkNgkM4d/5+9oJKZLOitfTOf9oKGYrMWG42K6vUPNfN3tE9uuUEzmPlYsuzOyHJXZVvPaBKHO65D3TNevX1/3GqgGAEAwTNizUunSpYveEsQk5DUAINp0CXFem91tBAAwds60umNevpXfv7gme1ZWtQdlbexZebI5c+bIxIkTZc2aNfLDDz+c8r0BABANc6adLtR5HfKeaQBA5AvFnOmTt1RS21WohUdMpHrKlUsvvbTCcTWTSs3HUjcEAACI9DnT0ZbXFNMAAOu8rp9aoOeKSG5uboU5WJVtueTUPStPtnr1ats+NwAAYcnsQHPewUKd144tpluvKJY6jr2608sZbfYCDkpMd/MX0nB9b+ZiOD4Ntpv/Byz+WvuG1daG9slmD88tKyqVfQ7eZ1oV0tUtaGLKnpUXX3yxRLPCbY2MXTS0ec+KN15MVHrC0BdM5XS9dquYbG2rLmK8BqdOtTFJ3Gf1xWgldY3fZ9oEoc5r8//6AgAimlpMLCMjQ/r06SN9+/bVC2advGflGWecobfC8u1ZqcJS7Vk5dOhQefnll/WelYsWLbLtGr/44otKj6shY2qva7X9VGU97wAAoPaEOq8ppgEAjt5n2ul7Virqmk63V2XdunX19/H000/rsAYAoLYwZ9q+vGY1bwBAWFbztkIN6f7666/1it8bNmzQe0/7qBU5Fy9eXOH5I0aMkOzsbP38L7/8Uq644gqxk9qrWRXtqvd7y5Ytuqn3O3bsqAv75557TlatWqULfAAAahWreduW1/RMAwCsC6JnOhLDefbs2fL444/r/ax9unXrJmeeeaZMnTpVPvnkE0lOTpYJEybIww8/HNZrBQBEmUAzm7yW6lBMAwDCsgBZJNm6dau0bt36lOPqmPqYb2jZgQMHwnB1AICoxgJktuU1w7wBAAhSp06d5MEHH5TS0lL/sbKyMn1MfUzZv3+/f543AAAwP6/pmQYAWEfPdAULFiyQK6+8Ug8T6969uz6m7nC73W5588039ePdu3fL73//+zBfKQAg6tAzbVteU0wDABy9mrcJ1Arie/bskaVLl8qOHTv8i6D9+te/lvr1f9r79Le//W2YrxIAEI1Yzdu+vKaYBgAgBFQI33777eG+DAAAUEt5TTENAECI/Pe//9X7Xpefi6WoIWUAACCy8ppiGgBgHXOmK1Dzq66++mo978rlconX+9M3qd5X1FwsAADCgjnTtuU1q3kDAAKefxVoizR33323tG3bVvLy8iQpKUm++uorWbdunfTp00fWrFkT7ssDAEQx8tq+vKZnGgAQmAgM2UCtX79eVq1aJU2aNJGYmBjdLrjgAsnKypJx48bJZ599Fu5LBABEMzLblrymZxoAEPiQsUBbhFHDwnyrgKqA/vbbb/X7rVu3luzs7DBfHQAgqpHXtuU1PdMAAASpa9eu8vnnn+uhY/369ZO5c+dKXFycLFq0SNq1axfuywMAABL6vKaYBgBYxj7TFU2ZMkWKior0+zNnzpRhw4bJhRdeKI0bN5aXX3453JcHAIhi7DNtX15TTAMArGM17woGDx7sf79Dhw6yfft2OXz4sDRs2NC/QigAAGHBat625TXFNADAMnqmf3LTTTfV6HnPP/+87dcCAEBl6JkW2/LascX0N7e4JSbJzH056+5JENPFHjO/J6XOMTGaN8b8v2ClJxz7J6ZGtq7pICbzFBfb98npmdYWL16sFy3p1auXf6/KaJTU8YjEJsWLiQ5kNxPTeVPKxHTbYjxispgS89f09RytKyZLv+xrMdmJohLZ+YhNn5yeabErr81+pQsAQBjdcccd8re//U327NkjY8aMkd/85jfSqFGjcF8WAACohbw2/zYaAKD2sTWWtmDBAjlw4IBMnDhR3njjDUlPT5frrrtO3n777ajuqQYAOAh5LXblNcU0ACDg+VeBtkgSHx8vN9xwg6xcuVL++9//yjnnnCO///3vpU2bNlJYWBjuywMARDny2r68Zpg3AMA65kxXKiYmRq8Gqu5yu91mrvsBAIgwzJm2La9t6Znev3+/Hoeu9utKTEyUbt26ycaNG+34UgCAcGCYt19JSYmeh3XZZZfJ2WefLVu3bpUnn3xS9u3bJ/Xq1RMnI68BIAqQ17bldch7pn/88Uc5//zz5ZJLLpH//Oc/0rRpU9m5c6feuwsAgEiihoe9/PLLeu6V2nZDhXSTJk3EBOQ1ACBa/N6mvA55MT1nzhx9kS+88IL/WNu2bUP9ZQAAYcQ+0z9ZuHChtGrVStq1aydr167VrTKvvvqqOA15DQDRgX2mxba8Dnkx/frrr8vgwYNlxIgR+iLPOOMMfSfg1ltvrbK7XTWfgoKCUF8SACDUmDOtjRo1Ss+5MpHVvFbIbAAwEHOmxa68DnkxvXv3bnnqqackMzNT/vjHP8qnn34q48aNk7i4OMnIyDjl+VlZWTJz5sxQXwYAwEb0TP9k8eLFYiqrea2Q2QBgHnqmxba8DvkCZB6PR84991z585//LL169ZLbbrtN3+VWXeuVmTx5suTn5/tbbm5uqC8JAAAEmdcKmQ0AgI090y1btpQuXbpUONa5c2f517/+VeV+X6oBAAzCMG/jWc1rhcwGAAMxzNucYlqtDJqdnV3h2I4dO6R169ah/lIAgHChmDYeeQ0AUYJi2jYhH+Z9zz33yMcff6yHjeXk5MhLL70kixYtkjvvvDPUXwoAECauIBvCj7wGgOjgxLw+fPiw3HjjjZKSkiINGjSQm2++WQoLC097zsCBA/UiYuXb7bffLhFVTJ933nmybNkyvXdX165dZdasWTJv3jz9wwIARNhd7kAbwo68BoAo4cC8vvHGG+Wrr76SlStXyptvvinr1q3Ta3dUR63tceDAAX+bO3euRNQwb+WXv/ylbgAAwLnIawBAbdu2bZusWLFC7yLRp08ffeyJJ56QK664Qh5++GFJS0ur8tykpCRp0aKFOEXIe6YBANGzzUagDQAA1A6n5fX69ev10G5fIa0MGjRIYmJiZMOGDac9d+nSpdKkSRM9okrtMHHs2DGJuJ5pAECEYwEyAACiYgGygoKCkO7scPDgQWnWrFmFY3Xq1JFGjRrpj1Xl17/+tV4kU/Vcf/HFF3LffffphTRfffVVCReKaQBAYCiKAQCI+MxOT0+v8Hj69OkyY8aMU543adIkmTNnTrVDvANVfk51t27d9BaPl156qezatUvOOussCQfHFtN1t9ST2PgEMdHxZh4xXb0+h8V0cXXcYrLjpXXFdEUFSWKyuBLD150ute/6gxn+xTDvyFNYmCAxHjMzO7XNETFd8/pHxXQ7tlZ8sW4ab8oJMV1cgxIx2Y5vmovJPMeLHZfZvnNyc3P1qts+VfVKT5gwQUaPHn3az9muXTs95zkvL6/C8RMnTugVvq3Mh+7Xr59+q3akoJgGAAAAADiKKqTLF9NVadq0qW7V6d+/vxw5ckQ2bdokvXv31sdWrVolHo/HXyDXxJYtW/Rb1UMdLixABgCwjq2xAAAwg8PyunPnznL55Zfrba4++eQT+fDDD2Xs2LEycuRI/0re+/fvl06dOumPK2oot9rCURXge/fulddff11GjRolF110kXTv3l3ChZ5pAIBlDPMGAMAMwQ7ztsPSpUt1Aa3mPKtVvK+55hqZP3++/+NlZWV6cTHfat1xcXHy7rvvyrx586SoqEjP41bnTJkyRcKJYhoAYB2reQMAEBWreduhUaNG8tJLL1X58TZt2ojX+78LUMXz2rVrxWkopgEAltEzDQCAGZzYMx0pmDMNAAAAAIBF9EwDAKxjmDcAAGZw4DDvSEExDQCwjmIaAAAzUEzbhmHeAICA518F2uxy+PBhufHGG/V+mA0aNJCbb75ZCgsLT3vOwIEDxeVyVWi33367fRcJAEAtcmJeRwp6pgEAEUMV0gcOHJCVK1fqbTXGjBkjt91222lXDFXUXpf333+//3FSUlItXC0AADAZxTQAICKGeW/btk1WrFghn376qfTp00cfe+KJJ+SKK66Qhx9+WNLS0qo8VxXPLVq0sOfCAAAIJ4Z524Zh3gAAy1xeb1BNKSgoqNBKSkqCuqb169frod2+QloZNGiQxMTEyIYNG0577tKlS6VJkybStWtXmTx5shw7diyoawEAwCmCzWtUjZ5pAEBYeqbT09MrHJ4+fbrMmDEj4Es6ePCgNGvWrMKxOnXqSKNGjfTHqvLrX/9aWrdurXuuv/jiC7nvvvskOztbXn311YCvBQAAx6Bn2jYU0wAAy4JZmMR3Xm5url4ozCc+Pr7S50+aNEnmzJlT7RDvQKk51T7dunWTli1byqWXXiq7du2Ss846K+DPCwCAyZnNAmTVo5gGAISFKqTLF9NVmTBhgowePfq0z2nXrp2e85yXl1fh+IkTJ/QK31bmQ/fr10+/zcnJoZgGAABVopgGADh6AbKmTZvqVp3+/fvLkSNHZNOmTdK7d299bNWqVeLxePwFck1s2bJFv1U91AAAGI9h3rZhATIAQETsM925c2e5/PLL9TZXn3zyiXz44YcyduxYGTlypH8l7/3790unTp30xxU1lHvWrFm6AN+7d6+8/vrrMmrUKLnooouke/fu9lwoAAC1yGl5HUnomQYARMTWWL5VuVUBreY8q1W8r7nmGpk/f77/42rvabW4mG+17ri4OHn33Xdl3rx5UlRUpBdFU+dMmTLFvosEAKA20TMdfcV0UZsTEpN4QkzUMC1fTNemwWExXfZ3FVf1NU2HJt+L6XI8TcRkiT8z+7+B+1hwW03ZvQCZHdTK3S+99FKVH2/Tpo14y231oYrntWvX2ndBUSL+q0SJjU8QIxUmiumye9QX0yV/a/ZgyeIexWK60h8M/R3+P4kHHFvW1IjbvshmATIbmf2XCwAAAACAMDD7Fg4AIDwcOswbAACchGHetqGYBgAEhOFfAACYgcy2B8U0AMA6Ne+43Nxjy+cCAABnZzZ5Hf450w8++KC4XC4ZP3683V8KABDFW2MhOOQ1AEQm8trQYvrTTz+Vp59+mr06AQBwMPIaAAAHFdOFhYVy4403yjPPPCMNGza068sAAMK5mEmgDY5BXgNAhCOvzSum77zzThk6dKgMGjTIri8BAAgTlye4BucgrwEgspHXhi1A9vLLL8vmzZv1sLHqlJSU6OZTUFBgxyUBAEKJrbEigpW8VshsADAQW2OZ0zOdm5srd999tyxdulQSEhKqfX5WVpakpqb6W3p6eqgvCQAQYixAZj6rea2Q2QBgHvLaoGJ606ZNkpeXJ+eee67UqVNHt7Vr18r8+fP1+263u8LzJ0+eLPn5+f6mwh0AANjLal4rZDYAADYO87700ktl69atFY6NGTNGOnXqJPfdd5/ExsZW+Fh8fLxuAACDsM+08azmtUJmA4CB2GfanGK6fv360rVr1wrHkpOTpXHjxqccBwCYKZjhXwwbcwbyGgCiQ6CZTV6HaQEyAECEYwEyAADMwAJktqmVYnrNmjW18WUAAEAQyGsAAGqOnmkAgGUM8wYAwAwM87YPxTQAwDoWIAMAwAwsQGYbimkAgGX0TAMAYAZ6pqOwmK5zNFZiyk7dlsMEbbocFtM1jDsupisz9N+Pzxdb24jpXCdcYrKW3faLyU54Suz75CxAhnLcvY6KJJWJiZo2KBDTHclpLqbz9s0Xk53VwOzrV/KS64nJ4tucEJO5ixyY2eR1tWKqfwoAAAAAADCiZxoA4FwM8wYAwAwM87YPxTQAwDqP96cW6LkAAMDZmU1eV4th3gCAwOdfBdoAAEDtcGBez549WwYMGCBJSUnSoEGDmn0bXq9MmzZNWrZsKYmJiTJo0CDZuXOnhBPFNADAMle5YWOWW7gvHgCAKBJwZtt4TaWlpTJixAi54447anzO3LlzZf78+bJw4ULZsGGDJCcny+DBg6W4uFjChWHeAAAAAIBaM3PmTP128eLFNe6VnjdvnkyZMkWGDx+ujy1ZskSaN28uy5cvl5EjR0o40DMNALDO6w2uAQCA2hEBeb1nzx45ePCgHtrtk5qaKv369ZP169eH7bromQYAWMZq3gAARMdq3gUFBRWOx8fH61abVCGtqJ7o8tRj38fCgZ5pAIB1LEAGAIAZgszr9PR03Qvsa1lZWZV+mUmTJonL5Tpt2759u0QSeqYBAJa5vF7dAj0XAAA4O7N95+Tm5kpKSor/eFW90hMmTJDRo0ef9nO2a9dOAtGiRQv99tChQ3o1bx/1uGfPnhIuFNMAAAAAgEqpQrp8MV2Vpk2b6maHtm3b6oL6vffe8xfPavi5WtXbyorgocYwbwCAdZ4gGwAAqB0OzOt9+/bJli1b9Fu3263fV62wsND/nE6dOsmyZcv0+2qI+Pjx4+WBBx6Q119/XbZu3SqjRo2StLQ0ueqqqyRc6JkGAFjGMG8AAKJjmLcdpk2bJi+++KL/ca9evfTb1atXy8CBA/X72dnZkp+f73/OxIkTpaioSG677TY5cuSIXHDBBbJixQpJSEiQcKGYBgBYF8xCYtTSAAA4P7NtzOvFixdXu8e02lu6PNU7ff/99+vmFAzzBgAAAADAInqmAQDWqbvFgQ7/Ypg3AADOz2zyuloU0wAAy1zen1qg5wIAAGdnNnldPYppAIB19EwDAGAGeqajr5j+zzWPS/36Zk7prh/j2B9rjdWLCd+qeKFSlr5WTPZCQbqYrkWdI2Kyr0vt2SuxthQXnpB1Nn1ul+enFui5iCxtmxyWuslxYqJfNvtCTPfLjtliuo+KzxCTfXS0g5hu1Jl7xGQPb79MTOY+4bbtcwea2eR19cysVgEAAAAACCPzu1ABALWPYd4AAJiBYd62oZgGAFjHPtMAAJjBgftMRwqKaQCAZS6vV7dAzwUAAM7ObPI6DHOms7Ky5LzzzpP69etLs2bN5KqrrpLsbPMXxgAAVDJkLNBmk9mzZ8uAAQMkKSlJGjRoUMNvxSvTpk2Tli1bSmJiogwaNEh27twpkY68BoAo4cC8jhQhL6bXrl0rd955p3z88ceycuVKKSsrk1/84hdSVFQU6i8FAEAFpaWlMmLECLnjjjtqfM7cuXNl/vz5snDhQtmwYYMkJyfL4MGDpbi4WCIZeQ0AgMOGea9YsaLC48WLF+s73ps2bZKLLroo1F8OABAO6mZ1oFtm2Hije+bMmf7sqdGleL0yb948mTJligwfPlwfW7JkiTRv3lyWL18uI0eOlEhFXgNAlAg0s+mYDv/WWPn5+fpto0aN7P5SAIBann8VaHOKPXv2yMGDB/XQbp/U1FTp16+frF+/XqIJeQ0AkSkS8joqFyDzeDwyfvx4Of/886Vr166VPqekpEQ3n4KCAjsvCQAQspVBA90aq/K/9/Hx8brVJlVIK6onujz12PexaFCTvFbIbACIosymlg5vz7Sai/Xll1/Kyy+/fNoFUFQvgK+lp6fbeUkAAIcsQKb+3pf/+6/yoDKTJk0Sl8t12rZ9+/Za/gFElprktUJmA4CBWIDMvJ7psWPHyptvvinr1q2TM888s8rnTZ48WTIzMyvc5SacASDy5ebmSkpKiv9xVb3SEyZMkNGjR5/2c7Vr1y6ga2jRooV+e+jQIb2at4963LNnT4kGNc1rhcwGAMDGYlot5nLXXXfJsmXLZM2aNdK2bdvTPj8cw/oAAEFSC5m4gjhXRBfS5YvpqjRt2lQ3O6iMUgX1e++95y+eVYGoVvW2siK4iazmtUJmA0AUZXagC41GkTp2DBV76aWX5LXXXtN7V/rmnKnhYGr/TgCA+YJZmMTOBU327dsnhw8f1m/dbrds2bJFH2/fvr3Uq1dPv9+pUyc9XPnqq6/WQ8TVXOEHHnhAOnTooAvKqVOnSlpamt53OZKR1wAQHQLNbBYgC0Mx/dRTT+m3AwcOrHD8hRdeqHaYHgDAEMHMpbIxnKdNmyYvvvii/3GvXr3029WrV/tzKTs7279ytTJx4kS9t/Jtt90mR44ckQsuuEBvG5WQkCCRjLwGgCgRaGZTTIdnmDcAAOGg9kqubo/pk3NK9U7ff//9ukUT8hoAAAdvjQUAiFAO7ZkGAAAnoWfaNhTTAADrKKYBADADxbRtKKYBAGFZzRsAANQCVvOOvmL6gDtOjrpjxER/yrlaTFfmiRXTjUjbJCYbkLRLTBcrZt/RXFXQRUxWWlwWdat5Izz+0X6lpNQ3M7O/Kj0upnvmx35iupGpn4rJpuYMF9ON7vuhmCy9wRExWVndUvnKps/Nat72MTP5AAAAAAAII8f2TAMAHIw50wAAmIE507ahmAYAWOfxqvFfgZ8LAACcndnkdbUopgEA1tEzDQCAGeiZtg3FNAAgAEEU04YvTAcAQHRkNnldHRYgAwAAAADAInqmAQDWMcwbAAAzMMzbNhTTAIAAFyVhATIAACI2s8nralFMAwCs83p+aoGeCwAAnJ3Z5HW1KKYBANYxzBsAADMwzNs2LEAGAAAAAIBF9EwDAKxjzjQAAGZgzrRtKKYBANYxzBsAADMwzNs2DPMGAFjnLRfOllu4Lx4AgCgScGbbd0mzZ8+WAQMGSFJSkjRo0KBG54wePVpcLleFdvnll0s40TMNAAAAAKg1paWlMmLECOnfv78899xzNT5PFc8vvPCC/3F8fLyEE8U0AMA6hnkDAGAGBw7znjlzpn67ePFiS+ep4rlFixbiFBTTAADrPGrvSU8Q5wIAAEdn9v/ldUFBwSkFbbh6hNesWSPNmjWThg0bys9//nN54IEHpHHjxhIuzJkGAFgX8HzpIHq0AQCAdUHmdXp6uqSmpvpbVlZWWL6Nyy+/XJYsWSLvvfeezJkzR9auXStDhgwRt9st4eLYnun7u/WWOq66YqKDy1PEdKVljv2nUWOPfjdITPZE3EAxXesppWKybX9IFZN5jheLyL/s+eQM80Y53d7OkJjEBDHSCZcYL9780R5L4/uKyWL3GPrvv5xr940XkyUdMPt32V2iMtuZw7xzc3MlJeV/9U1VvdKTJk3SRe7pbNu2TTp16mT9WkRk5MiR/ve7desm3bt3l7POOkv3Vl966aUSDuZXTAAAAAAAW6hCunwxXZUJEyboFbdPp127diG7LvW5mjRpIjk5ORTTAACDePQ+G0GcCwAAHJ3ZFvO6adOmutWWb775Rn744Qdp2bKlhAtzpgEAlnm9nqAaAACoHU7M63379smWLVv0WzXnWb2vWmFhof85ajj4smXL9Pvq+L333isff/yx7N27V8+bHj58uLRv314GDx4s4ULPNAAgsHlUgfYwM2caAADnZ7aNeT1t2jR58cUX/Y979eql365evVoGDvxp3aDs7GzJz8/X78fGxsoXX3yhzzly5IikpaXJL37xC5k1a1ZY95q2rWd6wYIF0qZNG0lISJB+/frJJ598YteXAgDUNlbzjhjkNQBEOAfmtdpf2uv1ntJ8hfRPl+31z8FOTEyUt99+W/Ly8qS0tFT3Ti9atEiaN28u4WRLMf3KK69IZmamTJ8+XTZv3iw9evTQ3e/qmwcAAM5AXgMA4LBi+tFHH5Vbb71VxowZI126dJGFCxdKUlKSPP/883Z8OQBAbfN4gmtwBPIaAKIAeW1OMa263Tdt2iSDBv1vj9+YmBj9eP369aH+cgCAcGCYt/HIawCIEuS1OQuQff/993pFtpPHr6vH27dvP+X5JSUluvkUFBSE+pIAACHm9XjE6wrsjjWreTuD1bxWyGwAiJ7MJq8N2BorKytLUlNT/S09PT3clwQAqA4901GJzAYAA5HX5hTTTZo00UuXHzp0qMJx9bhFixanPH/y5Ml6yXNfy83NDfUlAQCAIPNaIbMBALCxmI6Li5PevXvrjbR9PB6Pfty/f/9Tnq/2BUtJSanQAAAOp/arDKYh7KzmtUJmA4CByGtz5kwrapuNjIwM6dOnj/Tt21fmzZsnRUVFerVQAEAE0EO/ApxLxbAxxyCvASAKBJrZ5HV4iunrr79evvvuO5k2bZocPHhQevbsKStWrAj7ptoAgNDwerzidQUWsl7C2THIawCIfIFmNnkdpmJaGTt2rG4AgAikV/gMtGea1UGdhLwGgAgXaGaT185fzRsAAAAAANPY1jMNAIhcDPMGAMAMDPOOomLa9x/thJSJGPrfz32sREznLjshpvOcMHvghfuEW0x3wl0qJvMcL5ZIuH47wvCEtyTg4V/67zsigu/fltG/KydcYjyP+UMxXW6zM89l8K+Aj+kLN7tLzP5ddpc6L7PJ6+q5vA675fDNN99Ienp6uC8DACKG2gv4zDPPDMnnKi4ulrZt2+rFqoKh9jHes2ePJCQkhOS6EB5kNgBEdmaT14YV02qPy2+//Vbq168vLpc9d5gKCgp0+Kt/rCbukWn69UfC92D69UfC92D69dfG96D+vB89elTS0tIkJiZ0IzVUOJeWlga9xzHBbD67M5vf8/Az/foj4Xsw/foj4Xuojet3amaT14YN81b/eEJ1N6Y66pfBxF/oSLn+SPgeTL/+SPgeTL9+u7+H1NTUkH9OFaoEK2ozs/k9Dz/Trz8SvgfTrz8Svge7r5/MNo/Zk0oBAAAAAAgDimkAAAAAACyKymI6Pj5epk+frt+ayPTrj4TvwfTrj4TvwfTrj5TvAbBTJPyOmP49mH79kfA9mH79kfA9mH79iKIFyAAAAAAAcLqo7JkGAAAAACAYFNMAAAAAAFhEMQ0AAAAAgEUU0wAAAAAAWBR1xfSCBQukTZs2evPyfv36ySeffCKmWLdunQwbNkzS0tLE5XLJ8uXLxSRZWVly3nnnSf369aVZs2Zy1VVXSXZ2tpjkqaeeku7du0tKSopu/fv3l//85z9iqgcffFD/Wxo/fryYYsaMGfqay7dOnTqJSfbv3y+/+c1vpHHjxpKYmCjdunWTjRs3hvuyAMchs8PH9MyOtLxWyOzwILNxOlFVTL/yyiuSmZmpl7bfvHmz9OjRQwYPHix5eXligqKiIn3N6sWFidauXSt33nmnfPzxx7Jy5UopKyuTX/ziF/r7MsWZZ56pw2zTpk36D+nPf/5zGT58uHz11Vdimk8//VSefvpp/WLDNOecc44cOHDA3z744AMxxY8//ijnn3++1K1bV7+w++9//yuPPPKINGzYMNyXBjgKmR1epmd2JOW1QmaHB5mNanmjSN++fb133nmn/7Hb7fampaV5s7KyvKZR/+mWLVvmNVleXp7+PtauXes1WcOGDb3PPvus1yRHjx71dujQwbty5UrvxRdf7L377ru9ppg+fbq3R48eXlPdd9993gsuuCDclwE4HpntLJGQ2SbmtUJmhw+ZjepETc90aWmpvjs5aNAg/7GYmBj9eP369WG9tmiVn5+v3zZq1EhM5Ha75eWXX9Z36dXwMZOo3oahQ4dW+H0wyc6dO/XQyXbt2smNN94o+/btE1O8/vrr0qdPHxkxYoQeOtmrVy955plnwn1ZgKOQ2c5jcmabnNcKmR0+ZDaqEzXF9Pfff6//mDZv3rzCcfX44MGDYbuuaOXxePScHzV0pmvXrmKSrVu3Sr169SQ+Pl5uv/12WbZsmXTp0kVMoV5QqCGTaj6cidS8ycWLF8uKFSv0nLg9e/bIhRdeKEePHhUT7N69W193hw4d5O2335Y77rhDxo0bJy+++GK4Lw1wDDLbWUzNbNPzWiGzw4vMRnXqVPsMwKa7rF9++aVR82Z8OnbsKFu2bNF36f/5z39KRkaGnltmQkDn5ubK3Xffree/qQV9TDRkyBD/+2rumArq1q1by9///ne5+eabxYQXpeou95///Gf9WN3lVr8LCxcu1P+WAMBpTM1sk/NaIbPDj8xGdaKmZ7pJkyYSGxsrhw4dqnBcPW7RokXYrisajR07Vt58801ZvXq1XiDENHFxcdK+fXvp3bu3vlOsFph5/PHHxQRq2KRavOfcc8+VOnXq6KZeWMyfP1+/r3qCTNOgQQM5++yzJScnR0zQsmXLU17Ide7c2ahhb4DdyGznMDmzTc5rhcwOPzIb1YmaYlr9QVV/TN97770Kd5vUYxPnz5hIrcGiQlkNs1q1apW0bdtWIoH6d1RSUiImuPTSS/WwN3Wn3tfUHVc1h0m9r168mqawsFB27dqlA88EapjkydvL7NixQ9+pB/ATMjv8IjGzTcprhcwOPzIb1YmqYd5qiw01JEP9Ierbt6/MmzdPL0YxZswYMeUPUPk7eWreifpjqhYDadWqlZgwTOyll16S1157Te9b6Zv3lpqaqvftM8HkyZP1kCX181bzfdT3s2bNGj2PxgTq537yfLfk5GS9d6Ip8+D+8Ic/6L1bVZB9++23etsc9YLihhtuEBPcc889MmDAAD1k7LrrrtP75i5atEg3AP9DZoeX6Zltel4rZHb4kdmoljfKPPHEE95WrVp54+Li9LYbH3/8sdcUq1ev1ttSnNwyMjK8Jqjs2lV74YUXvKa46aabvK1bt9b/fpo2beq99NJLve+8847XZKZts3H99dd7W7Zsqf8bnHHGGfpxTk6O1yRvvPGGt2vXrt74+Hhvp06dvIsWLQr3JQGORGaHj+mZHYl5rZDZtY/Mxum41P9VX3IDAAAAAIComzMNAAAAAECoUEwDAAAAAGARxTQAAAAAABZRTAMAAAAAYBHFNAAAAAAAFlFMAwAAAABgEcU0AAAAAAAWUUwDAAAAAGARxTQAAAAAABZRTAMAAAAAYBHFNAAAAAAAFlFMAwAAAAAg1vx/SaNNCg3hoSUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example = data[0] \n",
    "plt.figure(figsize=(10,4))\n",
    "for ch in range(example.shape[0]):\n",
    "    plt.subplot(1, 2, ch+1)\n",
    "    plt.title(f'Channel {ch}')\n",
    "    plt.imshow(example[ch], aspect='auto', origin='lower')\n",
    "    plt.colorbar(label='Magnitude')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a304bda-4651-443d-8637-aa88caf7e18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data shape: (220000, 2, 17, 7)\n",
      "Combined labels shape: (220000,)\n",
      "Label map: {np.str_('8PSK'): 0, np.str_('AM-DSB'): 1, np.str_('AM-SSB'): 2, np.str_('BPSK'): 3, np.str_('CPFSK'): 4, np.str_('GFSK'): 5, np.str_('PAM4'): 6, np.str_('QAM16'): 7, np.str_('QAM64'): 8, np.str_('QPSK'): 9, np.str_('WBFM'): 10}\n"
     ]
    }
   ],
   "source": [
    "all_data_spect = []\n",
    "all_labels_spect = []\n",
    "keys_tuples = [eval(k) if isinstance(k, str) else k for k in Spectrogram_Processed.keys()]\n",
    "label_map = {mod: i for i, mod in enumerate(unique_modulations)}\n",
    "\n",
    "for key in keys_tuples:\n",
    "    modulation = key[0]\n",
    "    str_key = str(key)\n",
    "    data = Spectrogram_Processed[str_key]\n",
    "    all_data_spect.append(data)\n",
    "    \n",
    "    labels = np.full(data.shape[0], label_map[modulation])\n",
    "    all_labels_spect.append(labels)\n",
    "\n",
    "X = np.concatenate(all_data_spect, axis=0)\n",
    "y = np.concatenate(all_labels_spect, axis=0)\n",
    "\n",
    "print(f\"Combined data shape: {X.shape}\")\n",
    "print(f\"Combined labels shape: {y.shape}\")\n",
    "print(f\"Label map: {label_map}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a30dfae-87f7-4a90-8897-59f18bb83b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (132000, 2, 17, 7), (132000,)\n",
      "Validation shape: (44000, 2, 17, 7), (44000,)\n",
      "Test shape: (44000, 2, 17, 7), (44000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = split_sets(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fe52c40-846e-46a6-bb4e-8bba8c4acc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10]\n"
     ]
    }
   ],
   "source": [
    "LE = LabelEncoder()\n",
    "y_train_enc = LE.fit_transform(y_train)\n",
    "y_val_enc = LE.transform(y_val)\n",
    "y_test_enc = LE.transform(y_test)\n",
    "\n",
    "print(LE.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6be6a5b0-f07f-427e-ba62-67fcb192198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_spect = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train_enc, dtype=torch.long))\n",
    "val_dataset_spect = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val_enc, dtype=torch.long))\n",
    "test_dataset_spect = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test_enc, dtype=torch.long))\n",
    "\n",
    "train_loader_spect = DataLoader(train_dataset_spect, batch_size=64, shuffle=True)\n",
    "val_loader_spect = DataLoader(val_dataset_spect, batch_size=64, shuffle=False)\n",
    "test_loader_spect = DataLoader(test_dataset_spect, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a21b2a44-cf59-45f5-9470-1f55a790dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramPatchEncoder(nn.Module):\n",
    "    def __init__(self, in_channels=2, patch_size=(1, 1), embed_dim=128, img_size=(33, 3)):\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        self.num_patches = (img_size[0] // patch_size[0]) * (img_size[1] // patch_size[1])\n",
    "\n",
    "        self.proj = nn.Conv2d(\n",
    "            in_channels,\n",
    "            embed_dim,\n",
    "            kernel_size=patch_size,\n",
    "            stride=patch_size\n",
    "        )\n",
    "        \n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, self.num_patches + 1, embed_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.size(0)\n",
    "        x = self.proj(x) \n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
    "\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x = x + self.pos_embed\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8bbd1f70-abae-4b94-ad3c-a0ec60600a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramModel(nn.Module):\n",
    "    def __init__(self, in_channels=2, img_size=(17, 7), patch_size=(1, 2), embed_dim=256, num_classes=11):\n",
    "        super().__init__()\n",
    "        self.patch_encoder = SpectrogramPatchEncoder(\n",
    "            in_channels=in_channels,\n",
    "            patch_size=patch_size,\n",
    "            embed_dim=embed_dim,\n",
    "            img_size=img_size\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=embed_dim, nhead=8, dim_feedforward=256, batch_first=True),\n",
    "            num_layers=4\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(embed_dim, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.patch_encoder(x)\n",
    "        x = self.transformer(x)\n",
    "        x = x[:, 0]\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "786ea459-752e-4c77-8392-7441b229ef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\", \n",
    "    classes=np.unique(y_train_enc), \n",
    "    y=y_train_enc\n",
    ")\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor, label_smoothing=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c108aff7-48f1-4a9e-88f1-2f4c86ab002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Spectrogram_Model_V1 = SpectrogramModel(in_channels=2, img_size=(17, 7), patch_size=(1, 2), embed_dim=256,\n",
    "                                                 num_classes=11).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f164180-b38a-4552-9566-a4e27b8b572e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 1.983348 | Val Loss: 1.879537\n",
      "Epoch 2/50 | Train Loss: 1.867766 | Val Loss: 1.826203\n",
      "Epoch 3/50 | Train Loss: 1.821454 | Val Loss: 1.784803\n",
      "Epoch 4/50 | Train Loss: 1.803473 | Val Loss: 1.778803\n",
      "Epoch 5/50 | Train Loss: 1.790519 | Val Loss: 1.773808\n",
      "Epoch 6/50 | Train Loss: 1.782914 | Val Loss: 1.795271\n",
      "Epoch 7/50 | Train Loss: 1.774918 | Val Loss: 1.766638\n",
      "Epoch 8/50 | Train Loss: 1.768608 | Val Loss: 1.765053\n",
      "Epoch 9/50 | Train Loss: 1.763728 | Val Loss: 1.761574\n",
      "Epoch 10/50 | Train Loss: 1.760512 | Val Loss: 1.771174\n",
      "Epoch 11/50 | Train Loss: 1.756386 | Val Loss: 1.754052\n",
      "Epoch 12/50 | Train Loss: 1.754613 | Val Loss: 1.772113\n",
      "Epoch 13/50 | Train Loss: 1.751407 | Val Loss: 1.740493\n",
      "Epoch 14/50 | Train Loss: 1.749622 | Val Loss: 1.750428\n",
      "Epoch 15/50 | Train Loss: 1.747830 | Val Loss: 1.750025\n",
      "Epoch 16/50 | Train Loss: 1.745374 | Val Loss: 1.732953\n",
      "Epoch 17/50 | Train Loss: 1.742462 | Val Loss: 1.761796\n",
      "Epoch 18/50 | Train Loss: 1.740021 | Val Loss: 1.732473\n",
      "Epoch 19/50 | Train Loss: 1.739051 | Val Loss: 1.731109\n",
      "Epoch 20/50 | Train Loss: 1.737850 | Val Loss: 1.729040\n",
      "Epoch 21/50 | Train Loss: 1.735593 | Val Loss: 1.728631\n",
      "Epoch 22/50 | Train Loss: 1.735498 | Val Loss: 1.730051\n",
      "Epoch 23/50 | Train Loss: 1.734232 | Val Loss: 1.736254\n",
      "Epoch 24/50 | Train Loss: 1.731732 | Val Loss: 1.729511\n",
      "Epoch 25/50 | Train Loss: 1.731852 | Val Loss: 1.739559\n",
      "Epoch 26/50 | Train Loss: 1.712655 | Val Loss: 1.712810\n",
      "Epoch 27/50 | Train Loss: 1.711363 | Val Loss: 1.710774\n",
      "Epoch 28/50 | Train Loss: 1.709433 | Val Loss: 1.707281\n",
      "Epoch 29/50 | Train Loss: 1.709596 | Val Loss: 1.716738\n",
      "Epoch 30/50 | Train Loss: 1.709125 | Val Loss: 1.726972\n",
      "Epoch 31/50 | Train Loss: 1.708611 | Val Loss: 1.710444\n",
      "Epoch 32/50 | Train Loss: 1.707340 | Val Loss: 1.702679\n",
      "Epoch 33/50 | Train Loss: 1.707362 | Val Loss: 1.713752\n",
      "Epoch 34/50 | Train Loss: 1.705858 | Val Loss: 1.707766\n",
      "Epoch 35/50 | Train Loss: 1.705591 | Val Loss: 1.717803\n",
      "Epoch 36/50 | Train Loss: 1.705314 | Val Loss: 1.703116\n",
      "Epoch 37/50 | Train Loss: 1.694219 | Val Loss: 1.696449\n",
      "Epoch 38/50 | Train Loss: 1.693248 | Val Loss: 1.695323\n",
      "Epoch 39/50 | Train Loss: 1.692542 | Val Loss: 1.699615\n",
      "Epoch 40/50 | Train Loss: 1.691881 | Val Loss: 1.697268\n",
      "Epoch 41/50 | Train Loss: 1.690923 | Val Loss: 1.696778\n",
      "Epoch 42/50 | Train Loss: 1.691116 | Val Loss: 1.694024\n",
      "Epoch 43/50 | Train Loss: 1.690574 | Val Loss: 1.696969\n",
      "Epoch 44/50 | Train Loss: 1.690450 | Val Loss: 1.694315\n",
      "Epoch 45/50 | Train Loss: 1.690155 | Val Loss: 1.694339\n",
      "Epoch 46/50 | Train Loss: 1.690165 | Val Loss: 1.692217\n",
      "Epoch 47/50 | Train Loss: 1.689903 | Val Loss: 1.697540\n",
      "Epoch 48/50 | Train Loss: 1.689096 | Val Loss: 1.703029\n",
      "Epoch 49/50 | Train Loss: 1.688531 | Val Loss: 1.700201\n",
      "Epoch 50/50 | Train Loss: 1.688377 | Val Loss: 1.691890\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(Spectrogram_Model_V1.parameters(), lr=0.0001, weight_decay=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "train_losses_spect, val_losses_spect = train_model(model=Spectrogram_Model_V1, criterion=criterion, \n",
    "            optimizer=optimizer, epochs=50, train_loader=train_loader_spect, \n",
    "            val_loader=val_loader_spect, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30e66071-6079-40f0-8ef0-263ff8c7d9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.31      0.29      4000\n",
      "           1       0.56      0.63      0.59      4000\n",
      "           2       0.24      0.97      0.38      4000\n",
      "           3       0.58      0.54      0.56      4000\n",
      "           4       0.69      0.57      0.62      4000\n",
      "           5       0.83      0.57      0.68      4000\n",
      "           6       0.83      0.38      0.52      4000\n",
      "           7       0.28      0.04      0.06      4000\n",
      "           8       0.45      0.43      0.44      4000\n",
      "           9       0.35      0.17      0.23      4000\n",
      "          10       0.79      0.17      0.28      4000\n",
      "\n",
      "    accuracy                           0.43     44000\n",
      "   macro avg       0.53      0.43      0.42     44000\n",
      "weighted avg       0.53      0.43      0.42     44000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Spectrogram_Model_V1.eval()\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader_spect:\n",
    "        X_batch = X_batch.to(device)\n",
    "        outputs = Spectrogram_Model_V1(X_batch)\n",
    "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        y_pred.extend(preds)\n",
    "        y_true.extend(y_batch.numpy())\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=[str(c) for c in LE.classes_]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a2099b-21fb-4045-91c9-84472c109d04",
   "metadata": {},
   "source": [
    "The spectrogram transformer model was trained with patch_size=(3, 3), embed_dim=128, 4 transformer layers, and 8 attention heads using the Adam optimizer (lr=1e-4) over a maximum of 50 epochs with early stopping (patience=5).\n",
    "The best validation loss achieved was 1.6093, occurring at Epoch 12, after which performance plateaued and slightly degraded, indicating early signs of overfitting. This model achieved an accuracy of 39%. \n",
    "\n",
    "With in_channels=2, patch size (1, 1), and an embedding dimension of 256, the Spectrogram Transformer model trained over 50 epochs achieved a plateau in validation loss around epoch 20, indicating the need for architectural or regularization improvements to further enhance generalization.\n",
    "\n",
    "We trained a multi-class classification model on spectrogram data using a patch-based encoder with early stopping. Using current hyperparameters, the model achieved a validation loss of 1.5028, with a final test accuracy of 43%, and best per-class F1-scores in the range of 0.66–0.72 for 4 out of 11 classes, indicating strong performance on some signal types but difficulties with others (notably classes 1, 2, 7, and 10).\n",
    "\n",
    "Spectrograms were standardized using global channel-wise mean and standard deviation. The model employed a patch encoder with a patch size of (1, 2) and an embedding dimension of 256. A 4-layer Transformer with 8 attention heads and a feedforward dimension of 256 was used for feature extraction. Classification was performed using a LayerNorm, dropout of 0.3, and a final linear layer outputting 11 classes. Training used CrossEntropyLoss with label smoothing (0.1) and class weights to handle imbalance, optimized with Adam (learning rate 1e-4, weight decay 1e-4), and a ReduceLROnPlateau scheduler. After 25 epochs, the model achieved 50% test accuracy, outperforming the previous best by 7%, even without Gaussian noise or other augmentations.\n",
    "\n",
    "The model trained for 38 epochs with Gaussian noise augmentation (mean 0, std 0.05) on spectrogram inputs achieved about 49% accuracy, a slight drop from the baseline 50% without noise. Despite this, key classes maintained strong recall, notably class 2 at 95%, and mid-performing classes (3–6) kept solid F1 scores between 0.65 and 0.72. Importantly, recall for difficult classes like 7 improved from 7% to 15%, showing increased robustness. This indicates that adding Gaussian noise helps the model generalize better, particularly on challenging classes, and with longer training or additional augmentations, further gains are likely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7311f8f-217d-404e-8a30-1f39fe308018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
